{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50293bcf-fd74-4f6e-b748-84416535dd03",
   "metadata": {},
   "source": [
    "# Compute Orientation Selectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0141490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general python modules\n",
    "import sys, os, pprint, pandas\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from scipy import stats\n",
    "\n",
    "from physion.analysis.read_NWB import Data, scan_folder_for_NWBfiles\n",
    "import physion.utils.plot_tools as pt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # disable the UserWarning from pynwb (arrays are not well oriented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8872a177-d889-4c67-80d3-dd7691cf9db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_test_props = dict(interval_pre=[-1.,0],                                   \n",
    "                       interval_post=[1.,2.],                                   \n",
    "                       test='ttest',                                            \n",
    "                       positive=True)\n",
    "response_significance_threshold = 0.05\n",
    "\n",
    "def selectivity_index(angles, resp):\n",
    "    \"\"\"\n",
    "    computes the selectivity index: (Pref-Orth)/(Pref+Orth)\n",
    "    clipped in [0,1]\n",
    "    \"\"\"\n",
    "    imax = np.argmax(resp)\n",
    "    iop = np.argmin(((angles[imax]+90)%(180)-angles)**2)\n",
    "    if (resp[imax]>0):\n",
    "        return min([1,max([0,(resp[imax]-resp[iop])/(resp[imax]+resp[iop])])])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def shift_orientation_according_to_pref(angle,\n",
    "                                        pref_angle=0,\n",
    "                                        start_angle=-45,\n",
    "                                        angle_range=360):\n",
    "    new_angle = (angle-pref_angle)%angle_range\n",
    "    if new_angle>=angle_range+start_angle:\n",
    "        return new_angle-angle_range\n",
    "    else:\n",
    "        return new_angle\n",
    "\n",
    "\n",
    "def compute_tuning_response_per_cells(data,\n",
    "                                      imaging_quantity='dFoF',\n",
    "                                      prestim_duration=None,\n",
    "                                      stat_test_props=stat_test_props,\n",
    "                                      response_significance_threshold = response_significance_threshold,\n",
    "                                      contrast=1,\n",
    "                                      protocol_name='ff-gratings-8orientation-2contrasts-10repeats',\n",
    "                                      return_significant_waveforms=False,\n",
    "                                      verbose=True):\n",
    "\n",
    "    RESPONSES = []\n",
    "\n",
    "    protocol_id = data.get_protocol_id(protocol_name=protocol_name)\n",
    "\n",
    "    EPISODES = EpisodeData(data,\n",
    "                           quantities=[imaging_quantity],\n",
    "                           protocol_id=protocol_id,\n",
    "                           prestim_duration=prestim_duration,\n",
    "                           verbose=verbose)\n",
    "\n",
    "    shifted_angle = EPISODES.varied_parameters['angle']-\\\n",
    "                            EPISODES.varied_parameters['angle'][1]\n",
    "\n",
    "    significant_waveforms= []\n",
    "    significant = np.zeros(data.nROIs, dtype=bool)\n",
    "\n",
    "    for roi in np.arange(data.nROIs):\n",
    "\n",
    "        cell_resp = EPISODES.compute_summary_data(stat_test_props,\n",
    "                        response_significance_threshold=response_significance_threshold,\n",
    "                        response_args=dict(quantity=imaging_quantity, roiIndex=roi))\n",
    "\n",
    "        condition = (cell_resp['contrast']==contrast)\n",
    "\n",
    "        # if significant in at least one orientation\n",
    "        if np.sum(cell_resp['significant'][condition]):\n",
    "\n",
    "            significant[roi] = True\n",
    "\n",
    "            ipref = np.argmax(cell_resp['value'][condition])\n",
    "            prefered_angle = cell_resp['angle'][condition][ipref]\n",
    "\n",
    "            RESPONSES.append(np.zeros(len(shifted_angle)))\n",
    "\n",
    "            for angle, value in zip(cell_resp['angle'][condition],\n",
    "                                    cell_resp['value'][condition]):\n",
    "\n",
    "                new_angle = shift_orientation_according_to_pref(angle,\n",
    "                                                                pref_angle=prefered_angle,\n",
    "                                                                start_angle=-22.5,\n",
    "                                                                angle_range=180)\n",
    "                iangle = np.flatnonzero(shifted_angle==new_angle)[0]\n",
    "\n",
    "                RESPONSES[-1][iangle] = value\n",
    "\n",
    "            if return_significant_waveforms:\n",
    "                full_cond = EPISODES.find_episode_cond(\\\n",
    "                        key=['contrast', 'angle'],\n",
    "                        value=[contrast, prefered_angle])\n",
    "                significant_waveforms.append(getattr(EPISODES, imaging_quantity)[full_cond,roi,:].mean(axis=0))\n",
    "\n",
    "    if return_significant_waveforms:\n",
    "        return EPISODES.t, significant_waveforms\n",
    "    else:\n",
    "        return RESPONSES, significant, shifted_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fb0687",
   "metadata": {},
   "source": [
    "## Build the dataset from the NWB files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a209fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = scan_folder_for_NWBfiles(folder,\n",
    "                                   verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5c079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------- #\n",
    "# ----    Pick the session datafiles and sort ------ #\n",
    "# ----      them according to genotype ------------- #\n",
    "# -------------------------------------------------- #\n",
    "# -------------------------------------------------- #\n",
    "# ----    Pick the session datafiles and sort ------ #\n",
    "# ----      them according to genotype ------------- #\n",
    "# -------------------------------------------------- #\n",
    "\n",
    "def init_summary(DATASET):\n",
    "\n",
    "    SUMMARY = {'WT':{'FILES':[], 'subjects':[]}, \n",
    "               'GluN1':{'FILES':[], 'subjects':[]}, \n",
    "               'GluN3':{'FILES':[], 'subjects':[]},\n",
    "               # add a summary for half contrast\n",
    "               'WT_c=0.5':{'FILES':[]},\n",
    "               'GluN1_c=0.5':{'FILES':[]},\n",
    "               'GluN3_c=0.5':{'FILES':[]}}\n",
    "\n",
    "    for i, protocols in enumerate(DATASET['protocols']):\n",
    "\n",
    "        # select the sessions with different \n",
    "        if ('ff-gratings-8orientation-2contrasts-15repeats' in protocols) or\\\n",
    "            ('ff-gratings-8orientation-2contrasts-10repeats' in protocols):\n",
    "\n",
    "            # sort the sessions according to the mouse genotype\n",
    "            if ('NR1' in DATASET['subjects'][i]) or ('GluN1' in DATASET['subjects'][i]):\n",
    "                SUMMARY['GluN1']['FILES'].append(DATASET['files'][i])\n",
    "                SUMMARY['GluN1']['subjects'].append(DATASET['subjects'][i])\n",
    "            elif ('NR3' in DATASET['subjects'][i]) or ('GluN3' in DATASET['subjects'][i]):\n",
    "                SUMMARY['GluN3']['FILES'].append(DATASET['files'][i])\n",
    "                SUMMARY['GluN3']['subjects'].append(DATASET['subjects'][i])\n",
    "            else:\n",
    "                SUMMARY['WT']['FILES'].append(DATASET['files'][i])\n",
    "                SUMMARY['WT']['subjects'].append(DATASET['subjects'][i])\n",
    "                \n",
    "    return SUMMARY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1225d000",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY = init_summary(DATASET)\n",
    "for key in ['WT', 'GluN1']:\n",
    "    print('--------- %s -----------' % key)\n",
    "    for file, subject in zip(SUMMARY[key]['FILES'], SUMMARY[key]['subjects']):\n",
    "        print(' - %s : %s ' %(subject, file.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75318f4",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181f3d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------- #\n",
    "# ----   Loop over datafiles to compute    --------- #\n",
    "# ----           the evoked responses      --------- #\n",
    "# -------------------------------------------------- #\n",
    "\n",
    "def orientation_selectivity_index(resp_pref, resp_90):\n",
    "    \"\"\"                                                                         \n",
    "     computes the selectivity index: (Pref-Orth)/Pref\n",
    "     clipped in [0,1] --> because resp_90 can be negative    \n",
    "    \"\"\"\n",
    "    return (resp_pref-np.clip(resp_90, 0, np.inf))/resp_pref\n",
    "\n",
    "stat_test_props = dict(interval_pre=[-1.,0],                                   \n",
    "                       interval_post=[1.,2.],                                   \n",
    "                       test='ttest',                                            \n",
    "                       positive=True) \n",
    "    \n",
    "def compute_summary_responses(DATASET,\n",
    "                              quantity='dFoF',\n",
    "                              roi_to_neuropil_fluo_inclusion_factor=1.15,\n",
    "                              neuropil_correction_factor = 0.7,\n",
    "                              method_for_F0 = 'sliding_percentile',\n",
    "                              percentile=5., # percent\n",
    "                              sliding_window = 300, # seconds\n",
    "                              Nmax=999, # max datafiles (for debugging)\n",
    "                              stat_test_props=dict(interval_pre=[-1.,0],                                   \n",
    "                                                   interval_post=[1.,2.],                                   \n",
    "                                                   test='anova',                                            \n",
    "                                                   positive=True),\n",
    "                              response_significance_threshold=5e-2,\n",
    "                              verbose=True):\n",
    "    \n",
    "    SUMMARY = init_summary(DATASET)\n",
    "    \n",
    "    SUMMARY['quantity'] = quantity\n",
    "    SUMMARY['quantity_args'] = dict(roi_to_neuropil_fluo_inclusion_factor=\\\n",
    "                                        roi_to_neuropil_fluo_inclusion_factor,\n",
    "                                    method_for_F0=method_for_F0,\n",
    "                                    percentile=percentile,\n",
    "                                    sliding_window=sliding_window,\n",
    "                                    neuropil_correction_factor=neuropil_correction_factor)\n",
    "    \n",
    "    for key in ['WT', 'GluN1', 'GluN3']:\n",
    "\n",
    "        SUMMARY[key]['RESPONSES'], SUMMARY[key]['OSI'], SUMMARY[key]['FRAC_RESP'] = [], [], []\n",
    "        SUMMARY[key+'_c=0.5']['RESPONSES'], SUMMARY[key+'_c=0.5']['OSI'], SUMMARY[key+'_c=0.5']['FRAC_RESP'] = [], [], []\n",
    "\n",
    "        for f in SUMMARY[key]['FILES'][:Nmax]:\n",
    "\n",
    "            data = Data(f, verbose=False)\n",
    "            \n",
    "            print('analyzing \"%s\" [...] ' % f)\n",
    "            data = Data(f, verbose=False)\n",
    "\n",
    "            if quantity=='dFoF':\n",
    "                data.build_dFoF(roi_to_neuropil_fluo_inclusion_factor=\\\n",
    "                                        roi_to_neuropil_fluo_inclusion_factor,\n",
    "                                method_for_F0=method_for_F0,\n",
    "                                percentile=percentile,\n",
    "                                sliding_window=sliding_window,\n",
    "                                neuropil_correction_factor=neuropil_correction_factor,\n",
    "                                verbose=False)\n",
    "                \n",
    "            elif quantity=='rawFluo':\n",
    "                data.build_rawFluo(verbose=verbose)\n",
    "            elif quantity=='neuropil':\n",
    "                data.build_neuropil(verbose=verbose)            \n",
    "            else:\n",
    "                print('quantity not recognized !!')\n",
    "            \n",
    "            protocol = 'ff-gratings-8orientation-2contrasts-15repeats' if\\\n",
    "                        ('ff-gratings-8orientation-2contrasts-15repeats' in data.protocols) else\\\n",
    "                        'ff-gratings-8orientation-2contrasts-10repeats'\n",
    "\n",
    "            # at full contrast\n",
    "            responses, frac_resp, shifted_angle = compute_tuning_response_per_cells(data,\n",
    "                                                                                    imaging_quantity=quantity,\n",
    "                                                                                    contrast=1,\n",
    "                                                                                    protocol_name=protocol,\n",
    "                                                                                    stat_test_props=stat_test_props,\n",
    "                                                                                    response_significance_threshold=response_significance_threshold,\n",
    "                                                                                    verbose=False)\n",
    "            \n",
    "            SUMMARY[key]['RESPONSES'].append(responses)\n",
    "            SUMMARY[key]['OSI'].append([orientation_selectivity_index(r[1], r[5]) for r in responses])\n",
    "            SUMMARY[key]['FRAC_RESP'].append(frac_resp)\n",
    "\n",
    "            # for those two genotypes (not run for the GluN3-KO), we add:\n",
    "            if key in ['WT', 'GluN1']:\n",
    "                # at half contrast\n",
    "                responses, frac_resp, shifted_angle = compute_tuning_response_per_cells(data,\n",
    "                                                                                        contrast=0.5,\n",
    "                                                                                        protocol_name=protocol,\n",
    "                                                                                        stat_test_props=stat_test_props,\n",
    "                                                                                        response_significance_threshold=response_significance_threshold,\n",
    "                                                                                        verbose=False)\n",
    "                \n",
    "                SUMMARY[key+'_c=0.5']['RESPONSES'].append(responses)\n",
    "                SUMMARY[key+'_c=0.5']['OSI'].append([orientation_selectivity_index(r[1], r[5]) for r in responses])\n",
    "                SUMMARY[key+'_c=0.5']['FRAC_RESP'].append(frac_resp)\n",
    "                \n",
    "    SUMMARY['shifted_angle'] = shifted_angle\n",
    "    \n",
    "    return SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35521d27",
   "metadata": {},
   "source": [
    "## Varying the preprocessing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c595c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for quantity in ['rawFluo', 'neuropil', 'dFoF']:\n",
    "    SUMMARY = compute_summary_responses(DATASET, quantity=quantity, verbose=False)\n",
    "    np.save('../data/in-vivo/%s-ff-gratings.npy' % quantity, SUMMARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fbc8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for neuropil_correction_factor in [0.6, 0.7, 0.8, 0.9]:\n",
    "    SUMMARY = compute_summary_responses(DATASET, quantity='dFoF', \n",
    "                                   neuropil_correction_factor=neuropil_correction_factor,\n",
    "                                   verbose=False)\n",
    "    np.save('../data/in-vivo/factor-neuropil-%.1f-ff-gratings.npy' % neuropil_correction_factor, SUMMARY)\n",
    "    \n",
    "for roi_to_neuropil_fluo_inclusion_factor in [1.05, 1.1, 1.15, 1.2, 1.25, 1.3]:\n",
    "    SUMMARY = compute_summary_responses(DATASET, \n",
    "                                   quantity='dFoF', \n",
    "                                   roi_to_neuropil_fluo_inclusion_factor=roi_to_neuropil_fluo_inclusion_factor,\n",
    "                                   verbose=False)\n",
    "    np.save('../data/in-vivo/inclusion-factor-neuropil-%.1f-ff-gratings.npy' % roi_to_neuropil_fluo_inclusion_factor, SUMMARY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de03e1c1",
   "metadata": {},
   "source": [
    "## Quantification & Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba59c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def func(S, X):\n",
    "    \"\"\" fitting function \"\"\"\n",
    "    nS = (S+90)%180-90\n",
    "    return X[0]*np.exp(-(nS**2/2./X[1]**2))+X[2]\n",
    "\n",
    "def selectivity_index(resp1, resp2):\n",
    "    return (resp1-np.clip(resp2, 0, np.inf))/resp1\n",
    "\n",
    "def generate_comparison_figs(SUMMARY, \n",
    "                             cases=['WT'],\n",
    "                             average_by='ROIs',\n",
    "                             colors=['k', 'tab:blue', 'tab:green'],\n",
    "                             norm='',\n",
    "                             ms=1):\n",
    "    \n",
    "    fig, ax = plt.subplots(1, figsize=(2, 1))\n",
    "    plt.subplots_adjust(top=0.9, bottom=0.2, right=0.6)\n",
    "    inset = pt.inset(ax, (1.7, 0.2, 0.3, 0.8))\n",
    "\n",
    "    SIs = []\n",
    "    for i, key in enumerate(cases):\n",
    "\n",
    "        if average_by=='sessions':\n",
    "            resp = np.array([np.mean(r, axis=0) for r in SUMMARY[key]['RESPONSES']])\n",
    "        else:\n",
    "            resp = np.concatenate([r for r in SUMMARY[key]['RESPONSES']])\n",
    "        resp = np.clip(resp, 0, np.inf) # CLIP RESPONSIVE TO POSITIVE VALUES\n",
    "        \n",
    "        if norm!='':\n",
    "            resp = np.divide(resp, np.max(resp, axis=1, keepdims=True))\n",
    "            \n",
    "        SIs.append([selectivity_index(r[1], r[5]) for r in resp])\n",
    "\n",
    "        # data\n",
    "        pt.scatter(SUMMARY['shifted_angle']+2*i, np.mean(resp, axis=0),\n",
    "                   sy=stats.sem(resp, axis=0), ax=ax, color=colors[i], ms=ms)\n",
    "        \n",
    "        # fit\n",
    "        def to_minimize(x0):\n",
    "            return np.sum((resp.mean(axis=0)-\\\n",
    "                           func(SUMMARY['shifted_angle'], x0))**2)\n",
    "        \n",
    "        res = minimize(to_minimize,\n",
    "                       [0.8, 10, 0.2])\n",
    "        x = np.linspace(-30, 180-30, 100)\n",
    "        ax.plot(x, func(x, res.x), lw=2, alpha=.5, color=colors[i])\n",
    "\n",
    "        try:\n",
    "            if average_by=='sessions':\n",
    "                inset.annotate(i*'\\n'+'\\nN=%i %s (%i ROIs, %i mice)' % (len(resp),\n",
    "                                                    average_by, np.sum([len(r) for r in SUMMARY[key]['RESPONSES']]),\n",
    "                                                    len(np.unique(SUMMARY[key]['subjects']))),\n",
    "                               (0,0), fontsize=7,\n",
    "                               va='top',color=colors[i], xycoords='axes fraction')\n",
    "            else:\n",
    "                inset.annotate(i*'\\n'+'\\nn=%i %s (%i sessions, %i mice)' % (len(resp),\n",
    "                                                    average_by, len(SUMMARY[key]['RESPONSES']),\n",
    "                                                                    len(np.unique(SUMMARY[key]['subjects']))),\n",
    "                               (0,0), fontsize=7,\n",
    "                               va='top',color=colors[i], xycoords='axes fraction')\n",
    "        except BaseException as be:\n",
    "            pass\n",
    "            \n",
    "        \n",
    "    # selectivity index\n",
    "    for i, key in enumerate(cases):\n",
    "        pt.violin(SIs[i], X=[i], ax=inset, COLORS=[colors[i]])\n",
    "    if len(cases)==2:\n",
    "        inset.plot([0,1], 1.05*np.ones(2), 'k-', lw=0.5)\n",
    "        inset.annotate('Mann-Whitney: p=%.1e' % stats.mannwhitneyu(SIs[0], SIs[1]).pvalue,\n",
    "                       (0, 1.09), fontsize=6)\n",
    "    pt.set_plot(inset, xticks=[], ylabel='select. index', yticks=[0, 0.5, 1], ylim=[0, 1.09])\n",
    "\n",
    "    ylabel=norm+'$\\delta$ %s' % SUMMARY['quantity'].replace('dFoF', '$\\Delta$F/F')\n",
    "    pt.set_plot(ax, xlabel='angle ($^o$) from pref.',\n",
    "                ylabel=ylabel,\n",
    "                #yticks=[0.4,0.6,0.8,1],\n",
    "                xticks=SUMMARY['shifted_angle'],\n",
    "                xticks_labels=['%.0f'%s if (i%4==1) else '' for i,s in enumerate(SUMMARY['shifted_angle'])])\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "SUMMARY = np.load('../data/in-vivo/dFoF-ff-gratings.npy', allow_pickle=True).item()\n",
    "fig, ax = generate_comparison_figs(SUMMARY, ['WT', 'GluN1'], average_by='sessions', norm='norm. ')\n",
    "#fig.savefig(os.path.join(os.path.expanduser('~'), 'Desktop', 'poster-material', '1.svg'))\n",
    "fig, ax = generate_comparison_figs(SUMMARY, ['WT', 'GluN1'], average_by='ROIs', norm='norm. ')\n",
    "#fig.savefig(os.path.join(os.path.expanduser('~'), 'Desktop', 'poster-material', '2.svg'))\n",
    "fig, ax = generate_comparison_figs(SUMMARY, ['WT', 'WT_c=0.5'], average_by='ROIs', norm='norm. ',\n",
    "                                   colors=['k', 'tab:grey'])\n",
    "#fig.savefig(os.path.join(os.path.expanduser('~'), 'Desktop', 'poster-material', '3.svg'))\n",
    "fig, ax = generate_comparison_figs(SUMMARY, ['WT', 'WT_c=0.5'], average_by='sessions', norm='norm. ',\n",
    "                                   colors=['k', 'tab:grey'])\n",
    "ax.set_title('WT: full vs half contrast')\n",
    "#fig.savefig(os.path.join(os.path.expanduser('~'), 'Desktop', 'poster-material', '4.svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0625666",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, AX = plt.subplots(1, 2, figsize=(3,1))\n",
    "plt.subplots_adjust(wspace=0.9, right=0.8)\n",
    "inset = pt.inset(AX[1], [2.1, 0.3, 0.5, 0.7])\n",
    "for k, key, c, ax in zip(range(2), ['WT', 'GluN1'], ['k', 'tab:blue'], AX):\n",
    "    resp_c05 = np.concatenate([r for r in SUMMARY[key+'_c=0.5']['RESPONSES']])\n",
    "    resp_c1 = np.concatenate([r for r in SUMMARY[key]['RESPONSES']])\n",
    "    for index in [1,5]:\n",
    "        x, y = [0 ,0.5, 1], [0,np.mean(resp_c05[:, index]), np.mean(resp_c1[:, index])]\n",
    "        sy = [0,stats.sem(resp_c05[:, index]),stats.sem(resp_c1[:, index])]\n",
    "        ax.plot(x, y, '-' if index==1 else '--', color=c, label='pref.' if index==1 else 'orth.')\n",
    "        pt.scatter(x, y, sy=sy, ax=ax, color=c)\n",
    "        if index==1:\n",
    "            rel_increase = (np.mean(resp_c1[:,index])-np.mean(resp_c05[:,index]))/np.mean(resp_c05[:,index])\n",
    "            inset.bar([k], [np.mean(rel_increase)], color=c, alpha=1/index)\n",
    "    pt.set_plot(ax, xlabel='contrast', title=key, xticks=[0,0.5,1], ylabel='$\\delta$ $\\Delta$F/F')\n",
    "pt.set_plot(inset, ylabel='rel. increase\\n ($\\delta_{1}$-$\\delta_{0.5}$)/$\\delta_{0.5}$')\n",
    "AX[0].legend(frameon=False, loc=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baabcb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for quantity in ['rawFluo', 'neuropil', 'dFoF']:\n",
    "    SUMMARY = np.load('../data/%s-ff-gratings.npy' % quantity, allow_pickle=True).item()\n",
    "    _ = generate_comparison_figs(SUMMARY, ['WT', 'GluN1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857f70db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for neuropil_correction_factor in [0.6, 0.7, 0.8, 0.9, 1.]:\n",
    "    try:\n",
    "        SUMMARY = np.load('data/factor-neuropil-%.1f-ff-gratings.npy' % neuropil_correction_factor,\n",
    "                          allow_pickle=True).item()\n",
    "        fig, ax = generate_comparison_figs(SUMMARY, ['WT', 'GluN1'], norm='norm. ')    \n",
    "        ax.set_title('Neuropil-factor\\nfor substraction: %.1f' % neuropil_correction_factor)\n",
    "    except BaseException as be:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de319445",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "for roi_to_neuropil_fluo_inclusion_factor in [1.05, 1.1, 1.15, 1.2, 1.25, 1.3]:\n",
    "    SUMMARY = np.load('data/inclusion-factor-neuropil-%.1f-ff-gratings.npy' % roi_to_neuropil_fluo_inclusion_factor,\n",
    "                      allow_pickle=True).item()\n",
    "    fig, ax = generate_comparison_figs(SUMMARY, ['WT', 'GluN1'], norm='norm. ')    \n",
    "    ax.set_title('Roi/Neuropil\\ninclusion-factor: %.2f' % roi_to_neuropil_fluo_inclusion_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e5dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = generate_comparison_figs(SUMMARY, ['WT', 'WT_c=0.5'],\n",
    "                                   colors=['k', 'grey'], norm='norm. ')\n",
    "ax.set_title('WT: full vs half contrast');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5176d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = generate_comparison_figs(SUMMARY, ['GluN1', 'GluN1_c=0.5'],\n",
    "                                colors=['tab:blue', 'tab:cyan'], norm='norm. ')\n",
    "ax.set_title('GluN1: full vs half contrast');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d497436c",
   "metadata": {},
   "source": [
    "## Testing different \"visual-responsiveness\" criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f632109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most permissive\n",
    "SUMMARY = compute_summary_responses(stat_test_props=dict(interval_pre=[-1.,0],                                   \n",
    "                                                         interval_post=[1.,2.],                                   \n",
    "                                                         test='ttest',                                            \n",
    "                                                         positive=True),\n",
    "                                    response_significance_threshold=5e-2)\n",
    "FIGS = generate_comparison_figs(SUMMARY, 'WT', 'GluN1',\n",
    "                                color1='k', color2='tab:blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc80070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most strict\n",
    "SUMMARY = compute_summary_responses(stat_test_props=dict(interval_pre=[-1.5,0],                                   \n",
    "                                                         interval_post=[1.,2.5],                                   \n",
    "                                                         test='anova',                                            \n",
    "                                                         positive=True),\n",
    "                                    response_significance_threshold=1e-3)\n",
    "FIGS = generate_comparison_figs(SUMMARY, 'WT', 'GluN1',\n",
    "                                color1='k', color2='tab:blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2713b111",
   "metadata": {},
   "source": [
    "# Visualizing some evoked response in single ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bdcd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "sys.path.append('../physion/src')\n",
    "from physion.analysis.read_NWB import Data, scan_folder_for_NWBfiles\n",
    "from physion.analysis.process_NWB import EpisodeData\n",
    "from physion.utils import plot_tools as pt\n",
    "from physion.dataviz.episodes.trial_average import plot_trial_average\n",
    "sys.path.append('../')\n",
    "import plot_tools as pt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # disable the UserWarning from pynwb (arrays are not well oriented)\n",
    "\n",
    "def selectivity_index(angles, resp):\n",
    "    \"\"\"\n",
    "    computes the selectivity index: (Pref-Orth)/(Pref+Orth)\n",
    "    clipped in [0,1]\n",
    "    \"\"\"\n",
    "    imax = np.argmax(resp)\n",
    "    iop = np.argmin(((angles[imax]+90)%(180)-angles)**2)\n",
    "    if (resp[imax]>0):\n",
    "        return min([1,max([0,(resp[imax]-resp[iop])/(resp[imax]+resp[iop])])])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def cell_tuning_example_fig(filename,\n",
    "                            contrast=1.0,\n",
    "                            stat_test_props = dict(interval_pre=[-1,0], \n",
    "                                                   interval_post=[1,2],\n",
    "                                                   test='ttest',\n",
    "                                                   positive=True),\n",
    "                            response_significance_threshold = 0.01,\n",
    "                            Nsamples = 10, # how many cells we show\n",
    "                            seed=10):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    data = Data(filename)\n",
    "    \n",
    "    EPISODES = EpisodeData(data,\n",
    "                           quantities=['dFoF'],\n",
    "                           protocol_id=np.flatnonzero(['8orientation' in p for p in data.protocols]),\n",
    "                           with_visual_stim=True,\n",
    "                           verbose=True)\n",
    "    \n",
    "    fig, AX = pt.plt.subplots(Nsamples, len(EPISODES.varied_parameters['angle']), \n",
    "                          figsize=(7,7))\n",
    "    plt.subplots_adjust(right=0.75, left=0.1, top=0.97, bottom=0.05, wspace=0.1, hspace=0.8)\n",
    "    \n",
    "    for Ax in AX:\n",
    "        for ax in Ax:\n",
    "            ax.axis('off')\n",
    "\n",
    "    for i, r in enumerate(np.random.choice(np.arange(data.vNrois), \n",
    "                                           min([Nsamples, data.vNrois]), replace=False)):\n",
    "\n",
    "        # SHOW trial-average\n",
    "        plot_trial_average(EPISODES,\n",
    "                           condition=(EPISODES.contrast==contrast),\n",
    "                           column_key='angle',\n",
    "                           #color_key='contrast',\n",
    "                           #color=['lightgrey', 'k'],\n",
    "                           quantity='dFoF',\n",
    "                           ybar=1., ybarlabel='1dF/F',\n",
    "                           xbar=1., xbarlabel='1s',\n",
    "                           roiIndex=r,\n",
    "                           with_stat_test=True,\n",
    "                           stat_test_props=stat_test_props,\n",
    "                           with_screen_inset=True,\n",
    "                           AX=[AX[i]], no_set=False)\n",
    "        AX[i][0].annotate('roi #%i  ' % (r+1), (0,0), ha='right', xycoords='axes fraction')\n",
    "\n",
    "        # SHOW summary angle dependence\n",
    "        inset = pt.inset(AX[i][-1], (2.2, 0.2, 1.2, 0.8))\n",
    "\n",
    "        angles, y, sy, responsive_angles = [], [], [], []\n",
    "        responsive = False\n",
    "\n",
    "        for a, angle in enumerate(EPISODES.varied_parameters['angle']):\n",
    "\n",
    "            stats = EPISODES.stat_test_for_evoked_responses(episode_cond=\\\n",
    "                                            EPISODES.find_episode_cond(key=['angle', 'contrast'],\n",
    "                                                                       value=[angle, contrast]),\n",
    "                                                            response_args=dict(quantity='dFoF', roiIndex=r),\n",
    "                                                            **stat_test_props)\n",
    "\n",
    "            angles.append(angle)\n",
    "            y.append(np.mean(stats.y-stats.x))    # means \"post-pre\"\n",
    "            sy.append(np.std(stats.y-stats.x))    # std \"post-pre\"\n",
    "\n",
    "            if stats.significant(threshold=response_significance_threshold):\n",
    "                responsive = True\n",
    "                responsive_angles.append(angle)\n",
    "\n",
    "        pt.plot(angles, np.array(y), sy=np.array(sy), ax=inset)\n",
    "        inset.plot(angles, 0*np.array(angles), 'k:', lw=0.5)\n",
    "        inset.set_ylabel('$\\delta$ $\\Delta$F/F     ', fontsize=7)\n",
    "        inset.set_xticks(angles)\n",
    "        inset.set_xticklabels(['%i'%a if (i%2==0) else '' for i, a in enumerate(angles)], fontsize=7)\n",
    "        if i==(Nsamples-1):\n",
    "            inset.set_xlabel('angle ($^{o}$)', fontsize=7)\n",
    "\n",
    "        SI = selectivity_index(angles, y)\n",
    "        inset.annotate('SI=%.2f ' % SI, (1, 1), ha='right', style='italic', fontsize=6,\n",
    "                       color=('k' if responsive else 'lightgray'), xycoords='axes fraction')\n",
    "        \n",
    "    return fig\n",
    "\n",
    "folder = os.path.join(os.path.expanduser('~'), 'CURATED','SST-WT-NR1-GluN3-2023')\n",
    "fig = cell_tuning_example_fig(os.path.join(folder, '2023_02_15-13-30-47.nwb'),\n",
    "                             contrast=1, seed=21)\n",
    "#fig.savefig(os.path.join(os.path.expanduser('~'), 'Desktop', 'poster-material', '1.svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11ac972",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = cell_tuning_example_fig(SUMMARY['GluN1']['FILES'][2], seed=3)\n",
    "#fig.savefig(os.path.join(os.path.expanduser('~'), 'Desktop', 'poster-material', '1.svg'))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
